---
title: 프롬프트 엔지니어링 원칙 (Zero/Few-Shot, Chain-of-Thought)
date: '2025-07-03'
tags: [딥러닝, LLM, 프롬프트]
difficulty: easy
---

# 프롬프트 엔지니어링 원칙 (Zero/Few-Shot, Chain-of-Thought)

## 1. 핵심 개념 (Core Concept)

프롬프트 엔지니어링은 대규모 언어 모델(LLM)이 원하는 결과물을 생성하도록 입력 텍스트(프롬프트)를 설계하고 최적화하는 기술임. 이는 모델의 가중치를 직접 수정하는 파인튜닝(Fine-tuning)과 달리, 모델의 잠재된 능력을 최대한 이끌어내기 위해 입력 자체를 정교하게 구성하는 과정임. 효과적인 프롬프트는 모델의 성능과 결과물의 품질을 극적으로 향상시킬 수 있음.

______________________________________________________________________

## 2. 상세 설명 (Detailed Explanation)

### 2.1 In-Context Learning: Zero-Shot vs. Few-Shot

In-Context Learning은 LLM이 별도의 학습 없이 프롬프트에 포함된 예시(demonstration)를 통해 새로운 태스크를 학습하고 수행하는 능력을 의미함.

#### 2.1.1 Zero-Shot Prompting

- **개념**: 태스크에 대한 어떠한 예시도 제공하지 않고, 오직 태스크 설명만으로 모델이 응답하도록 하는 방식.
- **구조**: `[태스크 설명] + [입력]`
- **장점**: 간단하고 빠르게 프롬프트를 구성할 수 있음.
- **단점**: 복잡하거나 미묘한 태스크에 대해서는 성능이 낮을 수 있음.

#### 2.1.2 Few-Shot Prompting

- **개념**: 모델이 태스크를 더 잘 이해하고 원하는 출력 형식에 맞추도록, 몇 개의 예시(입력-출력 쌍)를 프롬프트에 포함하는 방식.
- **구조**: `[태스크 설명] + [예시 1] + [예시 2] + ... + [입력]`
- **장점**: Zero-shot보다 훨씬 높은 성능과 일관성을 보임. 모델이 출력의 형식, 내용, 스타일을 학습하게 함.
- **단점**: 프롬프트 길이가 길어져 비용이 증가하고, 컨텍스트 길이 제약에 걸릴 수 있음. 예시의 품질과 순서에 민감함.

| 구분              | Zero-Shot               | Few-Shot                               |
| :---------------- | :---------------------- | :------------------------------------- |
| **예시 제공**     | 없음                    | 1개 이상 (보통 1~5개)                  |
| **성능**          | 낮거나 중간             | 높음                                   |
| **적합한 태스크** | 간단한 분류, 요약, 번역 | 복잡한 추론, 코드 생성, 특정 형식 요구 |
| **프롬프트 길이** | 짧음                    | 김                                     |

### 2.2 Chain-of-Thought (CoT) Prompting

- **개념**: 복잡한 추론(산술, 상식, 기호 추론 등)이 필요한 문제에 대해, 모델이 최종 답변을 내리기 전에 **중간 추론 과정을 단계별로 생각하고 설명**하도록 유도하는 기법.
- **목적**: 모델이 성급하게 결론을 내리는 것을 방지하고, 문제 해결 과정을 명시적으로 전개하게 함으로써 더 정확하고 신뢰할 수 있는 답변을 생성하도록 함.
- **작동 원리**: "단계별로 생각해보자(Let's think step by step)"와 같은 문구를 추가하거나, Few-shot 예시에 추론 과정을 포함시켜 모델이 이를 모방하도록 함.

______________________________________________________________________

## 3. 예시 (Example)

### 프롬프트 템플릿 예시

#### Zero-Shot 예시

```
다음 문장의 감정을 "긍정", "부정", "중립" 중 하나로 분류하세요.

문장: 이 영화는 정말 환상적이었어! 배우들의 연기가 돋보였어.
감정:
```

#### Few-Shot 예시

```
다음 문장의 감정을 "긍정", "부정", "중립" 중 하나로 분류하세요.

문장: 배송이 너무 느려서 실망스러웠다.
감정: 부정

문장: 그냥 평범한 제품인 것 같다.
감정: 중립

문장: 이 영화는 정말 환상적이었어! 배우들의 연기가 돋보였어.
감정:
```

#### Chain-of-Thought (CoT) 예시

**기본 프롬프트 (CoT 없음)**

```
Q: 카페에 축구공이 15개 있었는데, 3상자를 더 들여왔습니다. 각 상자에는 5개의 축구공이 들어있습니다. 지금 카페에 있는 축구공은 총 몇 개인가요?
A: 20개 (오답)
```

**CoT 프롬프트 (Zero-Shot CoT)**

```
Q: 카페에 축구공이 15개 있었는데, 3상자를 더 들여왔습니다. 각 상자에는 5개의 축구공이 들어있습니다. 지금 카페에 있는 축구공은 총 몇 개인가요?

A: 단계별로 생각해보자.
1. 원래 있던 축구공은 15개이다.
2. 추가로 들여온 상자는 3상자이고, 각 상자에는 5개의 공이 들어있다.
3. 따라서 추가된 공의 수는 3 * 5 = 15개이다.
4. 원래 있던 15개와 새로 들여온 15개를 더하면 총 15 + 15 = 30개이다.
따라서 총 30개의 축구공이 있습니다. (정답)
```

______________________________________________________________________

## 4. 예상 면접 질문 (Potential Interview Questions)

- **Q. Few-shot 프롬프팅에서 예시(demonstration)의 품질이 왜 중요한가요? 예시를 선택할 때 고려해야 할 점은 무엇인가요?**
  - **A.** LLM은 제공된 예시의 패턴과 형식을 강력하게 모방하기 때문에 예시의 품질이 결과물에 직접적인 영향을 미칩니다. 고려할 점으로는 1) **정확성**: 예시의 입력-출력 쌍이 반드시 정확해야 합니다. 2) **일관성**: 모든 예시가 동일한 형식과 스타일을 유지해야 합니다. 3) **다양성**: 해결하려는 태스크의 다양한 측면을 보여줄 수 있는 예시들을 포함하는 것이 좋습니다. 4) **순서**: 최근 연구에 따르면 예시의 순서도 성능에 영향을 미칠 수 있으므로, 가장 관련성 높은 예시를 마지막에 두는 것이 효과적일 수 있습니다.
- **Q. Chain-of-Thought (CoT) 프롬프팅이 효과적인 이유는 무엇이며, 어떤 종류의 문제에 특히 유용한가요?**
  - **A.** CoT가 효과적인 이유는 모델이 복잡한 문제를 작은 단계로 분해하여 순차적으로 해결하도록 유도하기 때문입니다. 이는 사람의 문제 해결 방식과 유사하며, 각 단계에서 필요한 추론에 집중하게 하여 최종적인 오류 가능성을 줄입니다. 특히 산술 추론, 상식 추론, 기호 추리기와 같이 다단계 추론이 필요한 문제에서 매우 유용합니다.
- **Q. Zero-shot, Few-shot, Fine-tuning을 언제 각각 사용해야 할까요? 세 가지 접근 방식의 장단점을 비교 설명해주세요.**
  - **A.**
    - **Zero-shot**: 가장 빠르고 비용이 적게 드는 방법으로, 간단한 태스크나 프로토타이핑 단계에 적합합니다.
    - **Few-shot**: Zero-shot으로 성능이 부족하지만 파인튜닝까지는 필요 없을 때 사용합니다. 특정 출력 형식을 강제하거나 더 높은 정확도가 필요할 때 효과적입니다.
    - **Fine-tuning**: 대량의 데이터가 있고, 특정 도메인에 대한 깊은 지식이 필요하거나, 모델이 일관되게 특정 스타일이나 페르소나를 유지해야 할 때 사용합니다. 가장 비용과 시간이 많이 들지만 최고의 성능을 기대할 수 있습니다.
    - **비교**: Zero/Few-shot은 'In-context learning'으로 모델 자체를 바꾸지 않지만, Fine-tuning은 모델의 가중치를 업데이트하여 새로운 지식을 학습시킵니다.

______________________________________________________________________

## 5. 더 읽어보기 (Further Reading)

- [Language Models are Few-Shot Learners (Brown et al., 2020)](https://arxiv.org/abs/2005.14165) - Few-shot learning 개념 소개 논문
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (Wei et al., 2022)](https://arxiv.org/abs/2201.11903) - CoT 개념 소개 논문
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
