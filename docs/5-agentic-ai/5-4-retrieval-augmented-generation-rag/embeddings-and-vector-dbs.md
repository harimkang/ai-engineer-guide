---
title: "임베딩 및 벡터 데이터베이스 심화"
date: "2025-10-29"
tags: ["Agentic AI", "RAG", "Embeddings", "Vector DB", "HNSW"]
difficulty: "hard"
---

# 임베딩 및 벡터 데이터베이스 심화

## 1. 핵심 개념 (Core Concept)

임베딩(Embedding)은 텍스트 같은 비정형 데이터를 의미를 함축한 다차원 벡터(숫자 배열)로 변환하는 기술이며, 벡터 데이터베이스(Vector DB)는 이 벡터들을 효율적으로 저장하고 **의미 기반으로 유사한 벡터를 빠르게 검색**하는 시스템입니다. RAG 시스템의 성능은 어떤 임베딩 모델로 '의미 공간'을 구성하고, 어떤 벡터 DB와 인덱싱 전략으로 '검색 속도와 정확도'를 확보하느냐에 따라 크게 좌우됩니다.

*Note: 아래 다이어그램을 위한 이미지를 `docs/images/vector-space-search-diagram.png` 에 추가해주세요.*
![Vector Space Search Diagram](../../images/vector-space-search-diagram.png)

---

## 2. 상세 설명 (Detailed Explanation)

### 2.1 임베딩 모델 선택과 거리 측정 기준

- **임베딩 모델 선택 기준**: 처리할 언어(한국어/다국어), 전문 분야(법률/의료), 비용, 라이선스, 그리고 생성될 벡터의 차원 수(성능과 비용에 영향)를 종합적으로 고려해야 합니다.
- **거리 측정 기준**: 벡터 간의 '거리'를 계산하는 방식으로, 어떤 기준을 사용하느냐에 따라 유사성의 의미가 달라집니다.

| 거리 측정 기준 | 측정 대상 | 주요 사용 사례 | 비유 |
| :--- | :--- | :--- | :--- |
| **코사인 유사도** | **각도 / 방향** | 대부분의 텍스트 의미 검색. 문서 길이에 무관하게 주제의 유사성을 측정하는 데 가장 효과적. | 두 화살표가 같은 방향을 가리키는 정도. |
| **내적 (Dot Product)** | **각도 + 크기** | 추천 시스템 등 벡터의 크기(예: 선호도 강도)가 의미를 가질 때 사용. | 한 벡터가 다른 벡터에 드리운 그림자의 크기. |
| **유클리드 거리 (L2)** | **직선 거리** | 이미지 검색 등 벡터 공간 내 절대적 거리가 중요한 데이터에 사용. 텍스트에는 비교적 적게 사용됨. | 지도 위의 두 지점 간의 실제 물리적 거리. |

> **Note**: 대부분의 최신 임베딩 모델은 벡터를 정규화(L2-normalize)하여 출력하므로, 이 경우 코사인 유사도와 내적의 결과 순위는 사실상 동일해집니다.

### 2.2 벡터 인덱싱 알고리즘

수십억 개의 벡터 중에서 유사한 벡터를 빠르게 찾기 위해, 벡터 DB는 ANN(Approximate Nearest Neighbor) 인덱스라는 특수한 자료구조를 사용합니다.

- **IVF (Inverted File Index)**: 전체 벡터 공간을 여러 개의 구역(클러스터)으로 나눕니다. 검색 시, 쿼리 벡터가 속한 구역과 그 주변의 몇 개 구역(nprobe)만 탐색하여 속도를 높입니다. (비유: 서울시에서 특정 주소를 찾을 때, '강남구'라는 구역부터 찾고 그 안을 탐색하는 것)
- **HNSW (Hierarchical Navigable Small World)**: 여러 층으로 구성된 고속도로-일반도로망 같은 구조를 만듭니다. 검색 시, 처음에는 고속도로(상위 레이어)를 타고 목표 지점 근처로 빠르게 이동한 뒤, 일반도로(하위 레이어)로 내려와 정밀하게 탐색합니다. 검색 속도와 정확도가 모두 높아 널리 쓰이지만, 메모리 사용량이 큽니다.
- **PQ/OPQ (Product Quantization)**: 벡터를 압축하여 메모리 사용량을 획기적으로 줄이는 기법입니다. 벡터를 여러 조각으로 나눈 뒤, 각 조각을 미리 정의된 작은 코드북의 ID로 치환하여 저장합니다. 메모리 비용을 10배 이상 줄일 수 있지만, 원본 벡터가 손실되므로 검색 정확도가 약간 하락하는 트레이드오프가 있습니다.

### 2.3 하이브리드 검색과 재정렬

최상의 검색 품질을 위해 여러 기법을 결합합니다.

1.  **1단계 (후보 생성)**: BM25 같은 키워드 검색과 벡터 검색을 동시에 실행하여 각각의 후보군을 얻습니다.
2.  **2단계 (결합)**: 두 후보군의 순위를 RRF(Reciprocal Rank Fusion) 같은 기법으로 결합하여 초기 후보 목록을 만듭니다.
3.  **3단계 (재정렬)**: 이 후보 목록을 대상으로, 더 정교한 Cross-Encoder 모델을 적용하여 최종 순위를 매깁니다.

---

## 3. 예상 면접 질문 및 모범 답안

### Q1. 코사인 유사도, 내적, 유클리드 거리의 선택 기준은 무엇인가요?

**A.** 주로 다루는 데이터와 임베딩 모델의 특성에 따라 선택합니다. 대부분의 텍스트 기반 RAG에서는 문서 길이에 영향을 받지 않고 주제의 유사성을 잘 측정하는 **코사인 유사도**가 표준처럼 사용됩니다. 벡터의 크기 자체가 의미를 갖는 추천 시스템 등에서는 **내적**을, 이미지 데이터처럼 벡터 공간 내 절대 거리가 중요할 때는 **유클리드 거리**를 사용합니다.

**[추가 설명]**
중요한 점은 임베딩 모델이 어떤 거리 기준으로 학습되었는지 확인하는 것입니다. 또한, 최신 모델들은 대부분 벡터를 정규화(normalize)하여 출력하는데, 이 경우 모든 벡터의 길이가 1이 되므로 코사인 유사도와 내적의 결과 순위가 같아져 사실상 동일한 지표로 볼 수 있습니다.

### Q2. 하이브리드 검색에서 키워드 검색과 벡터 검색의 스코어를 어떻게 결합하나요?

**A.** 가중합(Weighted Sum) 방식도 있지만, 각 검색 시스템의 점수 척도가 달라 정규화가 어렵기 때문에, 최근에는 점수 대신 **순위(Rank)를 활용하는 RRF(Reciprocal Rank Fusion)** 방식이 더 널리 쓰입니다. RRF는 각 시스템에서의 순위를 역수로 변환하여 합산하므로, 특정 시스템의 점수 스케일에 영향을 받지 않고 안정적으로 결과를 결합할 수 있습니다.

**[추가 설명]**
- **가중합**: `최종 점수 = (1-α) * BM25_점수 + α * 벡터_점수` 방식으로, `α` 값을 튜닝해야 하는 번거로움과 각 점수를 정규화해야 하는 어려움이 있습니다.
- **RRF**: 각 문서의 최종 점수를 `1/(k+BM25_순위) + 1/(k+벡터_순위)` 와 같이 계산합니다. 순위만 사용하므로 구현이 간단하고, 파라미터 튜닝 없이도 준수한 성능을 보여 실용적입니다.
- **재정렬**: 가장 확실한 방법은 스코어를 결합하지 않고, 각 시스템의 상위 결과들을 모두 모아 더 강력한 재정렬 모델(Cross-Encoder)로 순위를 다시 매기는 것입니다. 품질은 가장 높지만 비용과 지연 시간이 증가합니다.

### Q3. PQ/OPQ 같은 벡터 압축 기술은 언제 적용하며, 어떤 손실을 감수해야 하나요?

**A.** PQ(Product Quantization)는 **수십억 개 이상의 벡터를 저장해야 해서 메모리(RAM) 비용이 감당하기 어려울 때** 적용하는 압축 기술입니다. 메모리 사용량을 10배 이상 획기적으로 줄일 수 있지만, 벡터를 압축하는 과정에서 원본 정보가 손실되므로 **검색 정확도(Recall)가 약간 하락하는 손실**을 감수해야 합니다.

**[추가 설명]**
- **적용 시점**: 10억 개의 1536차원 벡터는 약 6TB의 RAM을 필요로 합니다. 이처럼 인덱스를 메모리에 올리는 비용이 너무 커질 때, PQ는 정확도를 약간 희생하여 하드웨어 비용을 크게 절감하는 현실적인 선택지가 됩니다.
- **손실의 의미**: PQ는 벡터를 여러 조각으로 나눠, 각 조각을 근사값(미리 정의된 코드북의 ID)으로 대체합니다. 이 과정에서 원본 벡터의 정밀한 정보가 손실됩니다. 그 결과, 압축된 공간에서 찾은 최근접 이웃이 실제 원본 공간에서의 최근접 이웃과 다를 수 있어, 검색 재현율이 몇 퍼센트 정도 떨어질 수 있습니다.

### Q4. 임베딩 모델을 교체하거나, 시간이 지나 모델 성능이 저하(Drift)될 때 어떻게 대응해야 하나요?

**A.** 모델 **교체** 시에는 서비스 중단 없이 새 인덱스로 전환하는 **블루-그린 배포** 전략을 사용합니다. 점진적인 성능 저하, 즉 **드리프트**에 대응하기 위해서는, '골든 데이터셋'으로 **성능을 지속적으로 모니터링**하고, 성능이 일정 수준 이하로 떨어지면 경보를 울려 모델을 재학습시키거나 교체하도록 합니다.

**[추가 설명]**
- **모델 교체 전략 (블루-그린 배포)**:
  1.  (오프라인) 새 임베딩 모델이 기존 모델보다 우수함을 검증합니다.
  2.  (블루/운영) 기존 모델과 인덱스로 서비스를 계속 운영합니다.
  3.  (그린/배경) 전체 문서를 새 모델로 다시 임베딩하여 '그린 인덱스'를 완전히 새로 구축합니다.
  4.  (전환) 그린 인덱스가 준비되면, 애플리케이션의 트래픽을 블루에서 그린으로 전환합니다.
  5.  (제거) 그린 인덱스가 안정적으로 동작하는 것을 확인한 후, 기존 블루 인덱스를 제거합니다.
- **드리프트 대응 전략**:
  1.  **모니터링**: 대표적인 질문과 정답 문서 쌍으로 구성된 '골든 데이터셋'을 만듭니다.
  2.  **자동 평가**: 이 데이터셋으로 매주 또는 매일 Recall@k, NDCG 같은 검색 품질 지표를 자동으로 측정합니다.
  3.  **경보**: 만약 Recall@10 지표가 5% 이상 하락하는 등, 성능이 정해진 임계값 이하로 떨어지면 담당자에게 경보를 보냅니다.
  4.  **조치**: 경보가 울리면, 최신 데이터로 모델을 파인튜닝하거나, 더 성능 좋은 새 모델로 교체하는 작업을 검토하고 시작합니다.

---

## 5. See also

- [기본 RAG 파이프라인](./basic-rag-pipeline.md)
- [고급·Agentic RAG](./advanced-agentic-rag.md)