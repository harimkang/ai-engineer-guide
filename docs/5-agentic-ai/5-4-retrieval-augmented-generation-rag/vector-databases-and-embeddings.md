---
title: "벡터 데이터베이스 & 임베딩 (Vector Databases & Embeddings)"
date: "2025-07-06"
tags: ["Agentic AI", "RAG", "Vector Database", "Embeddings", "ANN"]
difficulty: "medium"
---

# 벡터 데이터베이스 & 임베딩 (Vector Databases & Embeddings)

## 1. 핵심 개념 (Core Concept)

**임베딩(Embeddings)**은 텍스트, 이미지 등 비정형 데이터를 LLM이 이해할 수 있는 고차원의 숫자 벡터로 변환하는 기술임. **벡터 데이터베이스(Vector Database)**는 이렇게 생성된 임베딩 벡터들을 효율적으로 저장하고, 특정 벡터와 의미적으로 가장 유사한 벡터들을 빠르게 검색(Similarity Search)하는 데 특화된 데이터베이스임. 이 두 가지 기술은 RAG 시스템에서 방대한 지식 베이스로부터 관련성 높은 정보를 신속하게 찾아내는 Retriever의 핵심 기반임.

---

## 2. 상세 설명 (Detailed Explanation)

### 2.1 임베딩: 의미를 숫자로 변환하기

LLM은 텍스트를 직접 이해하는 것이 아니라, 텍스트에 담긴 의미를 나타내는 숫자 벡터로 변환하여 처리함. 이 과정을 임베딩이라고 하며, 사전 학습된 언어 모델(Embedding Model)이 이 역할을 수행함.

*   **원리**: 의미적으로 유사한 단어나 문장은 벡터 공간에서도 서로 가까운 위치에 매핑됨. (예: '강아지', '개', '멍멍이'는 서로 가까운 벡터 값을 가짐)
*   **활용**: 사용자의 쿼리와 데이터베이스의 문서들을 모두 동일한 임베딩 모델을 사용하여 벡터로 변환함으로써, 의미 기반의 검색이 가능해짐.
*   **성능 향상**: Google의 "Agents Companions V2" 문서에서 언급된 것처럼, 일반적인 임베딩 모델 대신 특정 도메인의 데이터로 **임베딩 모델을 파인튜닝(Fine-tuning)**하거나 **검색 어댑터(Search Adaptor)**를 추가하면, 해당 도메인에 특화된 의미를 더 잘 포착하여 검색 품질을 크게 향상시킬 수 있음.

### 2.2 벡터 데이터베이스: 초고속 유사도 검색

수백만, 수십억 개의 벡터 중에서 주어진 쿼리 벡터와 가장 유사한 벡터를 실시간으로 찾아내는 것은 매우 어려운 작업임. 벡터 데이터베이스는 이를 효율적으로 처리하기 위해 **ANN(근사 근접 이웃, Approximate Nearest Neighbor)** 알고리즘을 사용함.

*   **ANN의 원리**: 100% 정확한 최근접 이웃을 찾는 대신, 약간의 오차를 허용하면서도 훨씬 빠른 속도로 거의 정확한 결과를 찾아내는 방식. 이를 위해 벡터들을 클러스터링하거나 그래프 구조로 구성하여 탐색 공간을 줄임.
*   **주요 ANN 알고리즘**:
    *   **HNSW (Hierarchical Navigable Small World)**: 계층적인 그래프 구조를 사용하여 빠르고 정확한 검색을 지원. 많은 최신 벡터 DB에서 사용됨.
    *   **IVF (Inverted File)**: 벡터들을 여러 개의 클러스터(버킷)로 나누고, 검색 시 가장 관련 있는 클러스터만 탐색함.

### 2.3 주요 벡터 데이터베이스 솔루션

| 솔루션 | 특징 | 주요 사용 사례 |
| :--- | :--- | :--- |
| **FAISS** | Facebook(Meta)에서 개발한 라이브러리. 빠르고 효율적인 인메모리(in-memory) 검색에 강점. | 연구, 프로토타이핑, 대규모 배치 처리. |
| **pgvector** | PostgreSQL의 확장 기능. 기존의 관계형 데이터와 벡터 데이터를 함께 저장하고 쿼리할 수 있음. | 기존 PostgreSQL 시스템에 벡터 검색 기능을 추가하고자 할 때. |
| **Milvus / Zilliz** | 대규모 프로덕션 환경을 위해 설계된 분산형 벡터 데이터베이스. 높은 확장성과 가용성을 제공. | 수십억 개 이상의 벡터를 다루는 대규모 상용 서비스. |
| **Pinecone** | 완전 관리형(fully-managed) 클라우드 네이티브 벡터 데이터베이스. 사용 편의성에 중점. | 인프라 관리 없이 빠르게 벡터 검색 기능을 도입하고 싶을 때. |
| **Vertex AI Vector Search** | Google Cloud의 완전 관리형 서비스. 초고속 검색과 확장성, Google의 AI 생태계와의 통합이 장점. | 대규모 엔터프라이즈 환경, Google Cloud 기반 서비스. |

---

## 3. 예시 (Example)

### 사용 사례: 영화 추천 시스템

*   **목표**: 사용자가 "반전이 있는 스릴러 영화"를 찾을 때, 관련 영화를 추천해주는 시나리오.

1.  **데이터 준비 및 임베딩**: 세상의 모든 영화 시놉시스를 임베딩 모델을 통해 벡터로 변환함.
2.  **벡터 DB 저장**: 변환된 영화 시놉시스 벡터들을 벡터 데이터베이스(예: Milvus)에 저장함. 각 벡터는 해당 영화의 ID와 연결됨.
3.  **쿼리 실행**: 사용자가 "반전이 있는 스릴러 영화"라고 검색하면, 이 쿼리 또한 동일한 임베딩 모델을 통해 벡터로 변환됨.
4.  **유사도 검색**: 벡터 DB는 이 쿼리 벡터와 가장 가까운 거리에 있는 영화 시놉시스 벡터들을 ANN 알고리즘을 통해 신속하게 찾아냄. (예: '식스 센스', '유주얼 서스펙트', '파이트 클럽' 등)
5.  **결과 반환**: 검색된 영화들의 ID를 바탕으로 포스터, 제목, 평점 등의 정보를 함께 사용자에게 보여줌.

---

## 4. 예상 면접 질문 (Potential Interview Questions)

*   **Q. 벡터 데이터베이스가 기존의 관계형 데이터베이스(RDBMS)와 다른 점은 무엇인가요?**
    *   **A.** RDBMS는 정형 데이터를 저장하고 SQL을 통해 정확한 조건(예: `WHERE name = 'John'`)으로 검색하는 데 최적화되어 있습니다. 반면, 벡터 데이터베이스는 텍스트나 이미지 같은 비정형 데이터를 변환한 고차원 벡터를 저장하고, '정확한 일치'가 아닌 '의미적 유사도'를 기준으로 데이터를 검색하는 데 특화되어 있습니다.

*   **Q. ANN(근사 근접 이웃)은 왜 '근사(Approximate)'라는 단어를 사용하며, 왜 이것이 중요한가요?**
    *   **A.** 수십억 개의 벡터 중에서 가장 유사한 벡터를 100% 정확하게 찾으려면 모든 벡터와 거리를 비교해야 해서 엄청난 계산 비용과 시간이 듭니다. ANN은 약간의 정확도를 희생하는 대신, HNSW 같은 효율적인 알고리즘을 사용하여 탐색 공간을 획기적으로 줄여 거의 실시간에 가까운 속도로 검색 결과를 반환합니다. 대부분의 애플리케이션에서는 100% 정확도보다 빠른 응답 속도가 더 중요하기 때문에 이 '근사' 방식이 매우 중요합니다.

*   **Q. 특정 도메인(예: 법률, 의료)에서 RAG 시스템의 검색 정확도를 높이려면 어떻게 해야 할까요?**
    *   **A.** 두 가지 접근법이 있습니다. 첫째는 데이터 전처리 단계에서 법률 또는 의료 용어사전을 활용하여 메타데이터를 풍부하게 추가하거나, 해당 도메인의 특성을 잘 반영하도록 청킹(chunking) 전략을 최적화하는 것입니다. 둘째는 모델 자체를 개선하는 것으로, 해당 도메인의 텍스트 데이터로 범용 임베딩 모델을 파인튜닝하여 도메인 특화적인 임베딩 모델을 만들면, 단어와 문장의 미묘한 의미 차이를 더 잘 포착하여 검색 정확도를 크게 높일 수 있습니다.

---

## 5. 더 읽어보기 (Further Reading)

*   [What is a Vector Database? by Milvus](https://milvus.io/docs/overview.md)
*   [Google AI Explains: Vector Embeddings](https://www.youtube.com/watch?v=y_2rVq_g-wE)
*   [Google Agent Document](/docs/assets/files/agentic-ai/google_agent.md)
*   [Anthropic Agent Document](/docs/assets/files/agentic-ai/anthropic_building_effective_ai_agents.md)