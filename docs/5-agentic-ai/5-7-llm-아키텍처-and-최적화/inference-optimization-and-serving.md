---
title: "추론 최적화 & 서빙: 양자화, vLLM/Ollama/TGI"
date: "2025-10-29"
tags: ["Agentic AI", "LLM", "Serving"]
difficulty: "medium"
---

# 추론 최적화 & 서빙

## 1. 핵심 개념 (Core Concept)

INT8/INT4 양자화, KV 캐시, 배칭 등으로 지연·비용을 줄이고, vLLM/Ollama/TGI 등 프레임워크로 운영성을 확보함.

---

## 2. 상세 설명 (Detailed Explanation)

### 2.1 양자화와 정확도 저하 관리
### 2.2 KV 캐시/배칭/동시성
### 2.3 서빙 프레임워크 선택 기준

---

## 3. 예시 (Example)

- vLLM 기반 다중 테넌트 서빙 개요.

---

## 4. 예상 면접 질문 (Potential Interview Questions)

- vLLM과 TGI 선택 기준은?

---

## 5. 더 읽어보기 (Further Reading)

- 4장 LLM 서빙·배포 관련 문서

