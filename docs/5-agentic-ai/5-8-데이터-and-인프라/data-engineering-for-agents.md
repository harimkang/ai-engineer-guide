---
title: '에이전트를 위한 데이터 엔지니어링: 수집, 합성, 품질 관리'
date: '2025-10-29'
tags: [Agentic AI, Data Engineering, Synthetic Data, LLMOps]
difficulty: hard
---

# 에이전트를 위한 데이터 엔지니어링

## 1. 핵심 개념 (Core Concept)

AI 에이전트의 성능은 전적으로 데이터의 품질에 달려있습니다. **"Garbage In, Garbage Out (쓰레기를 넣으면 쓰레기가 나온다)"** 원칙이 그 어느 때보다 중요합니다. 에이전트를 위한 데이터 엔지니어링은 **1) RAG를 위한 소스 데이터, 2) 파인튜닝을 위한 학습 데이터, 3) 테스트를 위한 평가 데이터**를 체계적으로 수집, 정제, 생성, 관리하는 전 과정을 의미합니다. 특히, 고품질의 데이터가 부족할 때 LLM을 활용해 데이터를 생성하는 **합성 데이터(Synthetic Data)** 기술과, 생성된 데이터의 품질을 관리하는 자동화된 파이프라인 구축이 핵심입니다.

*Note: 아래 다이어그램을 위한 이미지를 `docs/images/agent-data-flywheel.png` 에 추가해주세요.*
![Agent Data Flywheel Diagram](../../images/agent-data-flywheel.png)

______________________________________________________________________

## 2. 에이전트 데이터의 종류와 라이프사이클

### 2.1 소스 데이터 (Source Data for RAG)

- **목적**: 에이전트가 답변의 근거로 삼을 지식 베이스를 구축합니다.
- **라이프사이클**:
  1. **수집**: 내부 문서(Confluence, Google Drive), 데이터베이스, 웹사이트 등 다양한 소스로부터 원본 데이터를 수집합니다.
  1. **정제 및 표준화**: HTML 태그 제거, PDF에서 텍스트 추출 등 포맷을 정규화하고, 문서 ID, 출처 URL, 버전 등의 메타데이터를 부여합니다.
  1. **청킹 및 임베딩**: 정제된 문서를 RAG에 적합한 크기로 쪼개고(Chunking), 벡터로 변환하여 Vector DB에 색인합니다.

### 2.2 학습 데이터 (Training Data for Fine-tuning)

- **목적**: 모델이 특정 도메인의 스타일, 지식, 선호를 배우도록 파인튜닝(SFT, DPO 등)에 사용합니다.
- **라이프사이클**:
  1. **수집**: 사람이 직접 작성한 데이터, 또는 운영 중인 에이전트의 성공적인 궤적 로그를 수집합니다.
  1. **합성 및 증강**: 데이터가 부족할 경우, LLM을 활용해 데이터를 생성(합성)하거나, 기존 데이터를 변형(증강)하여 양을 늘립니다.
     - **합성 (Synthesis)**: LLM에게 역할(질문자/답변자)을 부여하여 대화 데이터를 생성(Self-play)하거나, 복잡한 질문을 하위 질문으로 분해하여 데이터(Self-ask)를 만듭니다.
     - **증강 (Augmentation)**: 기존 데이터의 단어를 유의어로 바꾸거나, 문장 구조를 변경하여 다양성을 확보합니다.
  1. **필터링 및 품질 관리**: 규칙 기반(욕설, 개인정보 필터) 및 LLM-as-a-Judge(논리성, 사실성 평가)를 통해 저품질의 합성/증강 데이터를 걸러냅니다.

### 2.3 평가 데이터 (Evaluation Data for Testing)

- **목적**: 모델과 프롬프트의 성능을 측정하고, 변경으로 인한 성능 저하(회귀)가 없는지 검증합니다.
- **라이프사이클**:
  1. **구축 (Curation)**: 가장 중요하고 대표적인 질문과 이상적인 답변으로 구성된 '골든 데이터셋'을 수작업으로 구축합니다. 일반적인 케이스와 엣지 케이스를 모두 포함해야 합니다.
  1. **분할 (Splitting)**: 데이터 누설을 방지하기 위해 학습/검증/테스트셋으로 엄격히 분리합니다. 특히, 시간에 따라 데이터 분포가 변하는 경우, 과거 데이터로 학습하고 미래 데이터로 테스트하는 '시간 기반 분할'이 필수적입니다.
  1. **버전 관리**: 모든 데이터셋은 명확한 버전(예: `golden_v1.2`)으로 관리하여, 모든 실험과 평가가 재현 가능하도록 보장합니다.

______________________________________________________________________

## 3. 예상 면접 질문 및 모범 답안

### Q1. 합성 데이터(Synthetic Data)에 포함될 수 있는 편향을 어떻게 완화할 수 있나요?

**A.** 합성 데이터의 편향은 **1) 다양한 시드(Seed) 데이터 사용, 2) 강력한 LLM 심판(Judge)을 통한 필터링, 3) 실제 사람의 데이터와 혼합 사용**을 통해 완화할 수 있습니다. 합성 데이터 생성에 사용되는 LLM 자체의 편향을 완전히 제거하기는 어렵기 때문에, 다층적인 검증과 희석 전략이 중요합니다.

**\[추가 설명\]**

1. **다양한 시드 데이터**: 데이터 생성의 시작점이 되는 시드 프롬프트가 다양해야 결과물의 다양성도 확보됩니다. 특정 관점에 치우치지 않은, 넓은 범위의 시드를 사용해야 합니다.
1. **편향성 검증 루브릭**: 데이터를 필터링하는 LLM 심판에게 '정확성'뿐만 아니라, '고정관념 포함 여부', '특정 그룹에 대한 편향된 시각' 등 편향성을 검사하는 구체적인 평가 기준(Rubric)을 제공해야 합니다.
1. **실제 데이터와 혼합**: 100% 합성 데이터에만 의존하는 것은 위험합니다. 소량이라도 사람이 직접 검수한 고품질의 실제 데이터를 섞어주면, 합성 데이터의 편향을 희석하고 모델의 안정성을 높일 수 있습니다.

### Q2. 데이터 누설(Data Leakage)을 방지하기 위한 데이터 분할 전략은 무엇인가요?

**A.** 데이터의 특성에 맞는 분할 전략을 사용해야 합니다. 데이터 포인트가 서로 독립적이라면 **무작위 분할**도 괜찮지만, 시간적 순서나 그룹핑(예: 동일한 사용자)이 중요하다면 **시간 기반 분할**이나 **그룹 기반 분할**을 사용해야만 데이터 누설을 막고 모델의 실제 성능을 올바르게 평가할 수 있습니다.

**\[추가 설명\]**

- **데이터 누설 문제**: 테스트셋에 있어야 할 정보가 학습셋에 포함되면, 모델이 정답을 미리 엿본 것과 같아 평가 점수가 비정상적으로 높게 나옵니다. 하지만 이런 모델은 실제 세상의 새로운 데이터에 대해서는 성능이 매우 낮게 나타납니다.
- **분할 전략**:
  - **시간 기반 분할**: 과거 데이터로 학습하고, 미래 데이터로 테스트합니다. (예: 1월~6월 데이터로 학습, 7월 데이터로 테스트)
  - **그룹 기반 분할**: 특정 사용자의 모든 대화 기록은 학습셋 아니면 테스트셋, 둘 중 한 곳에만 포함되도록 분할합니다. 이를 통해 모델이 특정 사용자의 말투에 과적합되는 것을 방지하고, 처음 보는 사용자에 대한 일반화 성능을 측정할 수 있습니다.
  - **중복 제거**: 분할 전에, 내용이 거의 동일한 데이터들을 해시나 임베딩 유사도를 통해 찾아내어 제거하는 과정이 반드시 선행되어야 합니다.

### Q3. 에이전트의 다중 턴 및 도구 사용 궤적(Trajectory) 데이터는 어떤 스키마로 정의해야 할까요?

**A.** 궤적 데이터는 **세션 단위의 최상위 정보**와, 그 안의 **각 턴(Turn)별 상세 정보를 담은 리스트** 형태의 계층적 스키마로 정의하는 것이 가장 좋습니다. 각 턴은 에이전트의 `thought`, `action`, `observation`을 구조화된 객체로 포함해야 합니다.

**\[추가 설명\]**

- **최상위 (세션) 스키마**:
  - `session_id`, `initial_query`, `final_outcome` (성공/실패), `final_answer`, `metadata` (사용자 ID, 타임스탬프 등)
  - `turns`: 아래의 턴 객체들이 담길 리스트
- **턴(Turn/Step) 스키마**:
  - `turn_number`: 턴의 순서 (예: 1, 2, 3, ...)
  - `thought`: 해당 턴에서 에이전트의 계획이나 내부 추론 과정 (문자열)
  - `action`: 에이전트가 수행한 행동. `{"tool_name": "search", "parameters": {"query": "..."}}` 와 같이 구조화된 객체.
  - `observation`: 행동의 결과. `{"status": "success", "output": "..."}` 와 같이 구조화된 객체.
- **장점**: 이렇게 구조화된 로그는 나중에 특정 도구가 실패한 궤적만 필터링하거나, 성공적인 `(thought, action)` 쌍만 추출하여 파인튜닝 데이터로 사용하는 등, 프로그래밍 방식의 분석과 재활용을 매우 용이하게 합니다.

______________________________________________________________________

## 4. See also

- [RAG 인덱싱](../5-4-retrieval-augmented-generation-rag/embeddings-and-vector-dbs.md)
- [파인튜닝 및 적응](../5-7-llm-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-and-%EC%B5%9C%EC%A0%81%ED%99%94/fine-tuning-and-adaptation.md)
- [평가 및 벤치마크](../5-5-%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81-and-%ED%8F%89%EA%B0%80/prompt-evaluation-and-benchmarks.md)
